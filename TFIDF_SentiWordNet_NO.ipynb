{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>user_total_karma</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_upvote_ratio</th>\n",
       "      <th>self_text</th>\n",
       "      <th>post_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cm3dnw7</td>\n",
       "      <td>1</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>2m33hb</td>\n",
       "      <td>Player276</td>\n",
       "      <td>0</td>\n",
       "      <td>75258.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>lol   title   can not deny   accusation</td>\n",
       "      <td>russia deny nato accusation   troop   ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cmqs3d9</td>\n",
       "      <td>1</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>2ov646</td>\n",
       "      <td>Martenz05</td>\n",
       "      <td>0</td>\n",
       "      <td>49520.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "      <td>article    estonian      english translation  ...</td>\n",
       "      <td>russia deny violate estonian airspace english ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cmv6omo</td>\n",
       "      <td>2</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>2p9hv1</td>\n",
       "      <td>CanadaDry95</td>\n",
       "      <td>0</td>\n",
       "      <td>7071.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>putin outsmart gt everybody</td>\n",
       "      <td>russias defense ministry   sunday deny swedish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codh5tc</td>\n",
       "      <td>1</td>\n",
       "      <td>UkrainePics</td>\n",
       "      <td>2ueefh</td>\n",
       "      <td>ms_kat_d</td>\n",
       "      <td>0</td>\n",
       "      <td>4046.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>highly idyllic stuff   nice</td>\n",
       "      <td>carpathian mountain western ukraine   vlad sok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covo4um</td>\n",
       "      <td>3</td>\n",
       "      <td>UkrainePics</td>\n",
       "      <td>2x06n4</td>\n",
       "      <td>I_AM_STILL_A_IDIOT</td>\n",
       "      <td>0</td>\n",
       "      <td>901387.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>thank   yougallowboob   share   album</td>\n",
       "      <td>unfortunate reality   war   eastern ukraine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cp2t1z0</td>\n",
       "      <td>3</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>2xrsz3</td>\n",
       "      <td>MaltyBeverage</td>\n",
       "      <td>0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.87</td>\n",
       "      <td>russia confirm putin   awesome russia confirm ...</td>\n",
       "      <td>russia deny cameras     nemtsovs murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cpv150u</td>\n",
       "      <td>2</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>30r8qq</td>\n",
       "      <td>The_Good_Stuffs</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>tend   believe   russians even      hard   b...</td>\n",
       "      <td>russia deny air traffic controller   fault   k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cxd26dh</td>\n",
       "      <td>4</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>3u39er</td>\n",
       "      <td>Xecutor</td>\n",
       "      <td>0</td>\n",
       "      <td>37976.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.88</td>\n",
       "      <td>russia deny      title russia deny    innocent</td>\n",
       "      <td>russia   innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cyg2591</td>\n",
       "      <td>6</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>3yq1af</td>\n",
       "      <td>chetmanly2</td>\n",
       "      <td>0</td>\n",
       "      <td>7065.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>russia also deny     finland</td>\n",
       "      <td>russia deny claim syriabound missile fall   iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d26j63i</td>\n",
       "      <td>1</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>4f7hcs</td>\n",
       "      <td>autotldr</td>\n",
       "      <td>0</td>\n",
       "      <td>3973420.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>well tldr   could make reduce       bot gt...</td>\n",
       "      <td>russia deny claim    jet barrelrolle   us reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d26omru</td>\n",
       "      <td>2</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>4f7hcs</td>\n",
       "      <td>imautoparts</td>\n",
       "      <td>0</td>\n",
       "      <td>258474.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>sound like somebody   dub topgun   russian vy ...</td>\n",
       "      <td>russia deny claim    jet barrelrolle   us reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d3a7izk</td>\n",
       "      <td>2</td>\n",
       "      <td>UkrainePics</td>\n",
       "      <td>4jvylu</td>\n",
       "      <td>I_AM_STILL_A_IDIOT</td>\n",
       "      <td>0</td>\n",
       "      <td>901387.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>put    title      know   resolution</td>\n",
       "      <td>uman ukraine    summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d3is27u</td>\n",
       "      <td>2</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>4kw5rk</td>\n",
       "      <td>upads</td>\n",
       "      <td>0</td>\n",
       "      <td>75150.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.90</td>\n",
       "      <td>russian helicopter     selfdestruct device  ...</td>\n",
       "      <td>russia deny lose helicopter   syrian base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d860ja5</td>\n",
       "      <td>1</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>4ylzbz</td>\n",
       "      <td>skate1243</td>\n",
       "      <td>0</td>\n",
       "      <td>20564.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>badass shit right</td>\n",
       "      <td>rio olympics   russia deny    involve   fatal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d8itgw7</td>\n",
       "      <td>6</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>568447</td>\n",
       "      <td>Patfanz</td>\n",
       "      <td>0</td>\n",
       "      <td>48207.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>pic    jet   radar coordinate   rcombatfoo...</td>\n",
       "      <td>russia deny violation   finland airspace   su ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d8jlt4n</td>\n",
       "      <td>2</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>56g5l0</td>\n",
       "      <td>TheAeolian</td>\n",
       "      <td>0</td>\n",
       "      <td>182474.0</td>\n",
       "      <td>85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>call</td>\n",
       "      <td>russia deny hack american political organisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d8juosg</td>\n",
       "      <td>11</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>56g5l0</td>\n",
       "      <td>Revelati123</td>\n",
       "      <td>0</td>\n",
       "      <td>297890.0</td>\n",
       "      <td>85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>fair          sure    even try anymore</td>\n",
       "      <td>russia deny hack american political organisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>d8ku97m</td>\n",
       "      <td>-1</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>56g5l0</td>\n",
       "      <td>neil_anblome</td>\n",
       "      <td>0</td>\n",
       "      <td>21520.0</td>\n",
       "      <td>85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>american could possibly complain   excessiv...</td>\n",
       "      <td>russia deny hack american political organisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d8lnrte</td>\n",
       "      <td>9</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>56p5z3</td>\n",
       "      <td>Dirk_Dirkler</td>\n",
       "      <td>0</td>\n",
       "      <td>39467.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.93</td>\n",
       "      <td>worry    nuclear capable missle    move wit...</td>\n",
       "      <td>russia deny anything insidious   move nuke   k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d8lwp1h</td>\n",
       "      <td>3</td>\n",
       "      <td>RussiaDenies</td>\n",
       "      <td>56p5z3</td>\n",
       "      <td>mrjderp</td>\n",
       "      <td>0</td>\n",
       "      <td>407838.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.93</td>\n",
       "      <td>want   test   shiny new nato missile defens...</td>\n",
       "      <td>russia deny anything insidious   move nuke   k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id  score     subreddit post_id         author_name  \\\n",
       "0     cm3dnw7      1  RussiaDenies  2m33hb           Player276   \n",
       "1     cmqs3d9      1  RussiaDenies  2ov646           Martenz05   \n",
       "2     cmv6omo      2  RussiaDenies  2p9hv1         CanadaDry95   \n",
       "3     codh5tc      1   UkrainePics  2ueefh            ms_kat_d   \n",
       "4     covo4um      3   UkrainePics  2x06n4  I_AM_STILL_A_IDIOT   \n",
       "5     cp2t1z0      3  RussiaDenies  2xrsz3       MaltyBeverage   \n",
       "6     cpv150u      2  RussiaDenies  30r8qq     The_Good_Stuffs   \n",
       "7     cxd26dh      4  RussiaDenies  3u39er             Xecutor   \n",
       "8     cyg2591      6  RussiaDenies  3yq1af          chetmanly2   \n",
       "9     d26j63i      1  RussiaDenies  4f7hcs            autotldr   \n",
       "10    d26omru      2  RussiaDenies  4f7hcs         imautoparts   \n",
       "11    d3a7izk      2   UkrainePics  4jvylu  I_AM_STILL_A_IDIOT   \n",
       "12    d3is27u      2  RussiaDenies  4kw5rk               upads   \n",
       "13    d860ja5      1  RussiaDenies  4ylzbz           skate1243   \n",
       "14    d8itgw7      6  RussiaDenies  568447             Patfanz   \n",
       "15    d8jlt4n      2  RussiaDenies  56g5l0          TheAeolian   \n",
       "16    d8juosg     11  RussiaDenies  56g5l0         Revelati123   \n",
       "17    d8ku97m     -1  RussiaDenies  56g5l0        neil_anblome   \n",
       "18    d8lnrte      9  RussiaDenies  56p5z3        Dirk_Dirkler   \n",
       "19    d8lwp1h      3  RussiaDenies  56p5z3             mrjderp   \n",
       "\n",
       "    controversiality  user_total_karma  post_score  post_upvote_ratio  \\\n",
       "0                  0           75258.0           5               0.57   \n",
       "1                  0           49520.0           5               0.62   \n",
       "2                  0            7071.0          14               0.75   \n",
       "3                  0            4046.0          20               1.00   \n",
       "4                  0          901387.0          18               0.93   \n",
       "5                  0           49800.0          17               0.87   \n",
       "6                  0              65.0           6               0.75   \n",
       "7                  0           37976.0          46               0.88   \n",
       "8                  0            7065.0          11               1.00   \n",
       "9                  0         3973420.0          17               0.95   \n",
       "10                 0          258474.0          17               0.95   \n",
       "11                 0          901387.0           8               1.00   \n",
       "12                 0           75150.0          31               0.90   \n",
       "13                 0           20564.0          20               0.95   \n",
       "14                 0           48207.0          98               0.97   \n",
       "15                 0          182474.0          85               0.88   \n",
       "16                 0          297890.0          85               0.88   \n",
       "17                 0           21520.0          85               0.88   \n",
       "18                 0           39467.0          59               0.93   \n",
       "19                 0          407838.0          59               0.93   \n",
       "\n",
       "                                            self_text  \\\n",
       "0             lol   title   can not deny   accusation   \n",
       "1   article    estonian      english translation  ...   \n",
       "2                         putin outsmart gt everybody   \n",
       "3                         highly idyllic stuff   nice   \n",
       "4               thank   yougallowboob   share   album   \n",
       "5   russia confirm putin   awesome russia confirm ...   \n",
       "6     tend   believe   russians even      hard   b...   \n",
       "7      russia deny      title russia deny    innocent   \n",
       "8                        russia also deny     finland   \n",
       "9       well tldr   could make reduce       bot gt...   \n",
       "10  sound like somebody   dub topgun   russian vy ...   \n",
       "11                put    title      know   resolution   \n",
       "12    russian helicopter     selfdestruct device  ...   \n",
       "13                                  badass shit right   \n",
       "14      pic    jet   radar coordinate   rcombatfoo...   \n",
       "15                                               call   \n",
       "16             fair          sure    even try anymore   \n",
       "17     american could possibly complain   excessiv...   \n",
       "18     worry    nuclear capable missle    move wit...   \n",
       "19     want   test   shiny new nato missile defens...   \n",
       "\n",
       "                                           post_title  \n",
       "0       russia deny nato accusation   troop   ukraine  \n",
       "1   russia deny violate estonian airspace english ...  \n",
       "2   russias defense ministry   sunday deny swedish...  \n",
       "3   carpathian mountain western ukraine   vlad sok...  \n",
       "4     unfortunate reality   war   eastern ukraine ...  \n",
       "5             russia deny cameras     nemtsovs murder  \n",
       "6   russia deny air traffic controller   fault   k...  \n",
       "7                                   russia   innocent  \n",
       "8    russia deny claim syriabound missile fall   iran  \n",
       "9   russia deny claim    jet barrelrolle   us reco...  \n",
       "10  russia deny claim    jet barrelrolle   us reco...  \n",
       "11                             uman ukraine    summer  \n",
       "12          russia deny lose helicopter   syrian base  \n",
       "13  rio olympics   russia deny    involve   fatal ...  \n",
       "14  russia deny violation   finland airspace   su ...  \n",
       "15   russia deny hack american political organisation  \n",
       "16   russia deny hack american political organisation  \n",
       "17   russia deny hack american political organisation  \n",
       "18  russia deny anything insidious   move nuke   k...  \n",
       "19  russia deny anything insidious   move nuke   k...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = \"D:\\\\Reddit_Comment_Project\\\\archive\\\\final_clean_5.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "display(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 'no text'\n",
    "df['self_text'].fillna('no text', inplace=True)\n",
    "\n",
    "# Fill NaN values with 'no text'\n",
    "df['post_title'].fillna('no text', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tfidf_matrix_self_text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     40\u001b[0m     row \u001b[38;5;241m=\u001b[39m tfidf_matrix_self_text\u001b[38;5;241m.\u001b[39mgetrow(idx)\n\u001b[1;32m---> 41\u001b[0m     sentiment_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_document_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_vectorizer_self_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     sentiment_scores\u001b[38;5;241m.\u001b[39mappend(sentiment_score)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Add sentiment scores to DataFrame\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m, in \u001b[0;36mcalculate_document_sentiment\u001b[1;34m(tfidf_vector, feature_names)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tfidf_vector):\n\u001b[0;32m     29\u001b[0m     word \u001b[38;5;241m=\u001b[39m feature_names[idx]\n\u001b[1;32m---> 30\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_word_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     document_sentiment \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m*\u001b[39m sentiment\n\u001b[0;32m     32\u001b[0m     total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weight\n",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m, in \u001b[0;36mget_word_sentiment\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_word_sentiment\u001b[39m(word):\n\u001b[1;32m---> 17\u001b[0m     synsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mswn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msenti_synsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(synsets) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Consider only the first synset (most common meaning)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m synsets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpos_score() \u001b[38;5;241m-\u001b[39m synsets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mneg_score()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\sentiwordnet.py:94\u001b[0m, in \u001b[0;36mSentiWordNetCorpusReader.senti_synsets\u001b[1;34m(self, string, pos)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[0;32m     93\u001b[0m sentis \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 94\u001b[0m synset_list \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m synset \u001b[38;5;129;01min\u001b[39;00m synset_list:\n\u001b[0;32m     96\u001b[0m     sentis\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msenti_synset(synset\u001b[38;5;241m.\u001b[39mname()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1757\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synsets\u001b[1;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1756\u001b[0m         pos \u001b[38;5;241m=\u001b[39m POS_LIST\n\u001b[1;32m-> 1757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_synset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_exceptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mform\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1760\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1756\u001b[0m         pos \u001b[38;5;241m=\u001b[39m POS_LIST\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   1758\u001b[0m         get_synset(p, offset)\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pos\n\u001b[1;32m-> 1760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m form \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_exceptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m offset \u001b[38;5;129;01min\u001b[39;00m index[form]\u001b[38;5;241m.\u001b[39mget(p, [])\n\u001b[0;32m   1762\u001b[0m     ]\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\corpus\\reader\\wordnet.py:2064\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   2036\u001b[0m MORPHOLOGICAL_SUBSTITUTIONS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2037\u001b[0m     NOUN: [\n\u001b[0;32m   2038\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     ADV: [],\n\u001b[0;32m   2060\u001b[0m }\n\u001b[0;32m   2062\u001b[0m MORPHOLOGICAL_SUBSTITUTIONS[ADJ_SAT] \u001b[38;5;241m=\u001b[39m MORPHOLOGICAL_SUBSTITUTIONS[ADJ]\n\u001b[1;32m-> 2064\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_morphy\u001b[39m(\u001b[38;5;28mself\u001b[39m, form, pos, check_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   2065\u001b[0m     \u001b[38;5;66;03m# from jordanbg:\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;66;03m# Given an original string x\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m     \u001b[38;5;66;03m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m     \u001b[38;5;66;03m# 2. Return all that are in the database\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;66;03m# 3. If there are no matches, keep applying rules until you either\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;66;03m#    find a match or you can't go any further\u001b[39;00m\n\u001b[0;32m   2072\u001b[0m     exceptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_map[pos]\n\u001b[0;32m   2073\u001b[0m     substitutions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMORPHOLOGICAL_SUBSTITUTIONS[pos]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Step 1: Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer_self_text = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit and Transform\n",
    "tfidf_matrix_self_text = tfidf_vectorizer_self_text.fit_transform(df['self_text'])\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "tfidf_df_self_text = pd.DataFrame(tfidf_matrix_self_text.toarray(), columns=tfidf_vectorizer_self_text.get_feature_names_out())\n",
    "\n",
    "# Step 4: Define Function to Get Word Sentiment\n",
    "def get_word_sentiment(word):\n",
    "    synsets = list(swn.senti_synsets(word))\n",
    "    if len(synsets) > 0:\n",
    "        # Consider only the first synset (most common meaning)\n",
    "        return synsets[0].pos_score() - synsets[0].neg_score()\n",
    "    else:\n",
    "        return 0.0  # If no synsets found, return neutral score\n",
    "\n",
    "# Step 5: Define Function to Calculate Document Sentiment\n",
    "def calculate_document_sentiment(tfidf_vector, feature_names):\n",
    "    document_sentiment = 0.0\n",
    "    total_weight = 0.0\n",
    "    for idx, weight in enumerate(tfidf_vector):\n",
    "        word = feature_names[idx]\n",
    "        sentiment = get_word_sentiment(word)\n",
    "        document_sentiment += weight * sentiment\n",
    "        total_weight += weight\n",
    "    if total_weight == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return document_sentiment / total_weight\n",
    "\n",
    "# Step 6: Apply SentiWordNet to TF-IDF vectors for self_text\n",
    "sentiment_scores = []\n",
    "for idx in range(tfidf_matrix_self_text.shape[0]):\n",
    "    row = tfidf_matrix_self_text.getrow(idx)\n",
    "    sentiment_score = calculate_document_sentiment(row.toarray()[0], tfidf_vectorizer_self_text.get_feature_names_out())\n",
    "    sentiment_scores.append(sentiment_score)\n",
    "\n",
    "# Add sentiment scores to DataFrame\n",
    "df['self_text_sentiment_swn'] = sentiment_scores\n",
    "\n",
    "# Display the DataFrame with sentiment scores\n",
    "print(df[['self_text', 'self_text_sentiment_swn']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# Step 1: Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer_post_title = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit and Transform\n",
    "tfidf_matrix_post_title = tfidf_vectorizer_post_title.fit_transform(df['post_title'])\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "tfidf_df_post_title = pd.DataFrame(tfidf_matrix_post_title.toarray(), columns=tfidf_vectorizer_post_title.get_feature_names_out())\n",
    "\n",
    "# Step 4: Define Function to Get Word Sentiment\n",
    "def get_word_sentiment(word):\n",
    "    synsets = list(swn.senti_synsets(word))\n",
    "    if len(synsets) > 0:\n",
    "        # Consider only the first synset (most common meaning)\n",
    "        return synsets[0].pos_score() - synsets[0].neg_score()\n",
    "    else:\n",
    "        return 0.0  # If no synsets found, return neutral score\n",
    "\n",
    "# Step 5: Define Function to Calculate Document Sentiment\n",
    "def calculate_document_sentiment(tfidf_vector, feature_names):\n",
    "    document_sentiment = 0.0\n",
    "    total_weight = 0.0\n",
    "    for idx, weight in enumerate(tfidf_vector):\n",
    "        word = feature_names[idx]\n",
    "        sentiment = get_word_sentiment(word)\n",
    "        document_sentiment += weight * sentiment\n",
    "        total_weight += weight\n",
    "    if total_weight == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return document_sentiment / total_weight\n",
    "\n",
    "# Step 6: Apply SentiWordNet to TF-IDF vectors for post_title\n",
    "def calculate_title_sentiment(comment_titles):\n",
    "    sentiment_scores = []\n",
    "    for idx in range(comment_titles.shape[0]):\n",
    "        row = comment_titles.getrow(idx)\n",
    "        sentiment_score = calculate_document_sentiment(row.toarray()[0], tfidf_vectorizer_post_title.get_feature_names_out())\n",
    "        sentiment_scores.append(sentiment_score)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Group by post_id and aggregate post titles\n",
    "grouped_titles = df.groupby('post_id')['post_title'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Calculate sentiment scores for aggregated titles\n",
    "title_sentiment_scores = calculate_title_sentiment(tfidf_vectorizer_post_title.transform(grouped_titles))\n",
    "\n",
    "# Add sentiment scores to DataFrame\n",
    "df['post_title_sentiment_swn'] = df['post_id'].map(grouped_titles.to_dict())\n",
    "df['post_title_sentiment_swn'] = title_sentiment_scores\n",
    "\n",
    "# Display the DataFrame with sentiment scores\n",
    "print(df[['post_title', 'post_title_sentiment_swn']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
